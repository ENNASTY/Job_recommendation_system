{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTgC6XHdTTnm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Charger les jeux de données\n",
        "jobs_data = pd.read_csv('/kaggle/input/anason/linkedin_jobs.csv')\n",
        "profiles_data = pd.read_csv('/kaggle/input/anason/upwork_profiles.csv')\n",
        "\n",
        "# Vérification des colonnes nécessaires et gestion des valeurs manquantes\n",
        "for df, name in zip([jobs_data, profiles_data], [\"jobs\", \"profiles\"]):\n",
        "    if 'describtion' not in df.columns or df['describtion'].isnull().any():\n",
        "        raise ValueError(f\"Le jeu de données {name} doit contenir une colonne 'describtion' non nulle.\")\n",
        "\n",
        "# Ajout d'IDs uniques si nécessaire\n",
        "if 'user_id' not in profiles_data.columns:\n",
        "    profiles_data['user_id'] = np.arange(1, len(profiles_data) + 1)\n",
        "\n",
        "if 'job_id' not in jobs_data.columns:\n",
        "    jobs_data['job_id'] = np.arange(1, len(jobs_data) + 1)\n",
        "\n",
        "# Étape 1 : Calcul de la similarité cosinus\n",
        "# TF-IDF pour les descriptions des utilisateurs et des emplois\n",
        "tfidf_jobs = TfidfVectorizer(max_features=100)\n",
        "job_tfidf_matrix = tfidf_jobs.fit_transform(jobs_data['describtion']).toarray()\n",
        "\n",
        "tfidf_profiles = TfidfVectorizer(max_features=100)\n",
        "profile_tfidf_matrix = tfidf_profiles.fit_transform(profiles_data['describtion']).toarray()\n",
        "\n",
        "# Calcul de similarité entre chaque utilisateur et chaque emploi\n",
        "similarity_matrix = cosine_similarity(profile_tfidf_matrix, job_tfidf_matrix)\n",
        "\n",
        "# Conversion de la matrice de similarité en matrice d'interaction binaire\n",
        "threshold = 0.5  # Seuil pour définir une correspondance\n",
        "interaction_data = pd.DataFrame(\n",
        "    np.where(similarity_matrix >= threshold, 1, 0),\n",
        "    index=profiles_data['user_id'],\n",
        "    columns=jobs_data['job_id']\n",
        ")\n",
        "\n",
        "# Conversion en format long (user_id, job_id, interaction)\n",
        "interaction_data = interaction_data.reset_index().melt(\n",
        "    id_vars=['user_id'],\n",
        "    var_name='job_id',\n",
        "    value_name='interaction'\n",
        ")\n",
        "\n",
        "# Étape 2 : Division des données en ensembles d'entraînement et de test\n",
        "train, test = train_test_split(interaction_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Étape 3 : Modèle DeepMF + Basé sur le contenu\n",
        "# Inputs\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "job_input = Input(shape=(1,), name='job_input')\n",
        "user_features_input = Input(shape=(profile_tfidf_matrix.shape[1],), name='user_features')\n",
        "job_features_input = Input(shape=(job_tfidf_matrix.shape[1],), name='job_features')\n",
        "\n",
        "# Embeddings pour DeepMF\n",
        "user_embedding = Embedding(input_dim=len(profiles_data) + 1, output_dim=50, name='user_embedding')(user_input)\n",
        "job_embedding = Embedding(input_dim=len(jobs_data) + 1, output_dim=50, name='job_embedding')(job_input)\n",
        "\n",
        "user_vector = Flatten(name='user_vector')(user_embedding)\n",
        "job_vector = Flatten(name='job_vector')(job_embedding)\n",
        "\n",
        "# Fusionner les embeddings et les représentations textuelles\n",
        "concat_embeddings = Concatenate()([user_vector, job_vector])\n",
        "concat_features = Concatenate()([user_features_input, job_features_input])\n",
        "\n",
        "# Fusion finale\n",
        "concat_all = Concatenate()([concat_embeddings, concat_features])\n",
        "\n",
        "# Fully connected layers\n",
        "dense_1 = Dense(128, activation='relu')(concat_all)\n",
        "dropout_1 = Dropout(0.3)(dense_1)\n",
        "dense_2 = Dense(64, activation='relu')(dropout_1)\n",
        "output = Dense(1, activation='sigmoid', name='output')(dense_2)\n",
        "\n",
        "# Compilation du modèle\n",
        "model = Model(inputs=[user_input, job_input, user_features_input, job_features_input], outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Résumé du modèle\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Étape 1 : Préparation des données d'entrée\n",
        "# Remapper les identifiants des utilisateurs et des emplois pour qu'ils soient contigus (nécessaire pour Embedding)\n",
        "user_id_map = {user_id: idx for idx, user_id in enumerate(profiles_data['user_id'], start=1)}\n",
        "job_id_map = {job_id: idx for idx, job_id in enumerate(jobs_data['job_id'], start=1)}\n",
        "\n",
        "train['user_id'] = train['user_id'].map(user_id_map)\n",
        "train['job_id'] = train['job_id'].map(job_id_map)\n",
        "test['user_id'] = test['user_id'].map(user_id_map)\n",
        "test['job_id'] = test['job_id'].map(job_id_map)\n",
        "\n",
        "# Entrées pour l'entraînement\n",
        "X_train = [\n",
        "    train['user_id'].values,\n",
        "    train['job_id'].values,\n",
        "    profile_tfidf_matrix[train['user_id'] - 1],  # Représentations utilisateurs\n",
        "    job_tfidf_matrix[train['job_id'] - 1],      # Représentations emplois\n",
        "]\n",
        "y_train = train['interaction'].values\n",
        "\n",
        "# Entrées pour le test\n",
        "X_test = [\n",
        "    test['user_id'].values,\n",
        "    test['job_id'].values,\n",
        "    profile_tfidf_matrix[test['user_id'] - 1],  # Représentations utilisateurs\n",
        "    job_tfidf_matrix[test['job_id'] - 1],      # Représentations emplois\n",
        "]\n",
        "y_test = test['interaction'].values\n",
        "\n",
        "# Étape 2 : Entraînement du modèle\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Étape 3 : Évaluation du modèle\n",
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Calcul des métriques\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Optionnel : Visualisation des courbes d'apprentissage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b9CLoTk7Tfy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fonction pour prédire les jobs pour un utilisateur en fonction d'une description\n",
        "def predict_jobs_for_user(user_description, jobs_data, tfidf_jobs, model):\n",
        "    # Prétraiter la description utilisateur avec le même vecteur TF-IDF utilisé pour les profils\n",
        "    user_vector = tfidf_profiles.transform([user_description]).toarray()\n",
        "\n",
        "    # Créer des données d'entrée pour chaque job dans jobs_data\n",
        "    user_input_data = np.array([0] * len(jobs_data))  # ID utilisateur fictif (0) car c'est un nouvel utilisateur\n",
        "    job_input_data = jobs_data['job_id'].values  # IDs des emplois\n",
        "    user_features_data = np.repeat(user_vector, len(jobs_data), axis=0)  # Répéter les features utilisateur\n",
        "    job_features_data = job_tfidf_matrix  # Features des jobs (TF-IDF)\n",
        "\n",
        "    # Faire des prédictions\n",
        "    predictions = model.predict([user_input_data, job_input_data, user_features_data, job_features_data])\n",
        "\n",
        "    # Ajouter les prédictions dans jobs_data pour afficher les résultats\n",
        "    jobs_data['match_probability'] = predictions\n",
        "    jobs_data = jobs_data.sort_values(by='match_probability', ascending=False)\n",
        "\n",
        "    return jobs_data[['job_id', 'jobs_titles', 'match_probability']].head(5)  # Top 5 des jobs recommandés\n",
        "\n",
        "# Exemple : Entrée utilisateur\n",
        "print(\"Entrez une description de votre profil (exemple : compétences, expérience) :\")\n",
        "user_description = input()\n",
        "\n",
        "# Prédire les jobs pour cette description utilisateur\n",
        "recommended_jobs = predict_jobs_for_user(user_description, jobs_data, tfidf_jobs, model)\n",
        "\n",
        "# Afficher les recommandations\n",
        "print(\"\\nJobs recommandés pour vous :\")\n",
        "print(recommended_jobs)\n"
      ],
      "metadata": {
        "id": "IDMRN7rdT6Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcZDqp8hT6Qh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}